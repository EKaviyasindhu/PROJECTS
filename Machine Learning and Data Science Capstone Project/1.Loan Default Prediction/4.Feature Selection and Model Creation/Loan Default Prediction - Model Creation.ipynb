{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0060d338-1535-473e-95f6-154e3e37bc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 1. Imports\n",
    "# ========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de2dd94f-8222-4f00-8c13-dcc5424a8bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 2. Load Preprocessed Data\n",
    "# ========================\n",
    "df = pd.read_csv(\"Prep_Loan_default.csv\")\n",
    "\n",
    "X = df.drop(columns=[\"Default\"])\n",
    "y = df[\"Default\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8668bc6a-0c49-47d5-b8c1-677e0391f9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 3. Base Pipeline - Feature Engineering\n",
    "# ========================\n",
    "# Common preprocessing steps for all models\n",
    "base_steps = [\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"selector\", SelectKBest(score_func=f_classif, k=20)),  # tune k if needed\n",
    "    (\"pca\", PCA(n_components=10, random_state=42))          # tune n if needed\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74195ac1-8329-4e5a-941e-81fc094ed2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 4. Define Models & Hyperparameters\n",
    "# ========================\n",
    "models = {\n",
    "    \"Logistic Regression\": (\n",
    "        Pipeline(base_steps + [(\"model\", LogisticRegression(max_iter=1000, random_state=42))]),\n",
    "        {\"model__C\": [0.01, 0.1, 1, 10], \"model__penalty\": [\"l2\"]}\n",
    "    ),\n",
    "    \"Random Forest\": (\n",
    "        Pipeline(base_steps + [(\"model\", RandomForestClassifier(random_state=42))]),\n",
    "        {\"model__n_estimators\": [10, 20], \"model__max_depth\": [3, 5, None]}\n",
    "    ),\n",
    "    \"XGBoost\": (\n",
    "        Pipeline(base_steps + [(\"model\", XGBClassifier(eval_metric=\"logloss\", random_state=42))]),\n",
    "        {\"model__n_estimators\": [10, 20], \"model__max_depth\": [3, 5]}\n",
    "    ),\n",
    "    #\"SVM\": (\n",
    "    #    Pipeline(base_steps + [(\"model\", SVC(probability=True, random_state=42))]),\n",
    "    #    {\"model__C\": [0.1, 1, 10], \"model__kernel\": [\"linear\", \"rbf\"]}\n",
    "    #),\n",
    "    #\"KNN\": (\n",
    "    #    Pipeline(base_steps + [(\"model\", KNeighborsClassifier())]),\n",
    "    #    {\"model__n_neighbors\": [3, 5, 7], \"model__weights\": [\"uniform\", \"distance\"]}\n",
    "    #),\n",
    "    \"Gradient Boosting\": (\n",
    "        Pipeline(base_steps + [(\"model\", GradientBoostingClassifier(random_state=42))]),\n",
    "        {\"model__n_estimators\": [10, 20], \"model__learning_rate\": [0.05, 0.1]}\n",
    "    ),\n",
    "    \"Naive Bayes\": (\n",
    "        Pipeline(base_steps + [(\"model\", GaussianNB())]),\n",
    "        {}  # no hyperparameters\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "389504fb-ea16-4e41-a133-06d50d06fe8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression ...\n",
      "Logistic Regression -> Accuracy: 0.8839, F1: 0.8295, Params: {'model__C': 0.01, 'model__penalty': 'l2'}\n",
      "\n",
      "Training Random Forest ...\n",
      "Random Forest -> Accuracy: 0.8839, F1: 0.8294, Params: {'model__max_depth': 3, 'model__n_estimators': 10}\n",
      "\n",
      "Training XGBoost ...\n",
      "XGBoost -> Accuracy: 0.8839, F1: 0.8307, Params: {'model__max_depth': 5, 'model__n_estimators': 20}\n",
      "\n",
      "Training Gradient Boosting ...\n",
      "Gradient Boosting -> Accuracy: 0.8839, F1: 0.8294, Params: {'model__learning_rate': 0.05, 'model__n_estimators': 10}\n",
      "\n",
      "Training Naive Bayes ...\n",
      "Naive Bayes -> Accuracy: 0.8839, F1: 0.8295, Params: {}\n",
      "\n",
      "==== Model Comparison ====\n",
      "                 Model  Accuracy  F1 Score  \\\n",
      "0  Logistic Regression  0.883904  0.829473   \n",
      "4          Naive Bayes  0.883885  0.829463   \n",
      "1        Random Forest  0.883865  0.829378   \n",
      "2              XGBoost  0.883865  0.830730   \n",
      "3    Gradient Boosting  0.883865  0.829378   \n",
      "\n",
      "                                         Best Params  \n",
      "0         {'model__C': 0.01, 'model__penalty': 'l2'}  \n",
      "4                                                 {}  \n",
      "1  {'model__max_depth': 3, 'model__n_estimators':...  \n",
      "2  {'model__max_depth': 5, 'model__n_estimators':...  \n",
      "3  {'model__learning_rate': 0.05, 'model__n_estim...  \n",
      "\n",
      "Final pipeline saved as final_pipeline.pkl (Logistic Regression)\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# 5. Train, Tune & Compare\n",
    "# ========================\n",
    "results = []\n",
    "best_models = {}\n",
    "\n",
    "for name, (pipe, params) in models.items():\n",
    "    print(f\"\\nTraining {name} ...\")\n",
    "    if params:\n",
    "        grid = GridSearchCV(pipe, params, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
    "        grid.fit(X_train, y_train)\n",
    "        best_model = grid.best_estimator_\n",
    "        best_params = grid.best_params_\n",
    "    else:\n",
    "        best_model = pipe.fit(X_train, y_train)\n",
    "        best_params = {}\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    \n",
    "    print(f\"{name} -> Accuracy: {acc:.4f}, F1: {f1:.4f}, Params: {best_params}\")\n",
    "    \n",
    "    results.append({\"Model\": name, \"Accuracy\": acc, \"F1 Score\": f1, \"Best Params\": best_params})\n",
    "    best_models[name] = best_model\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"Accuracy\", ascending=False)\n",
    "print(\"\\n==== Model Comparison ====\")\n",
    "print(results_df)\n",
    "\n",
    "# ========================\n",
    "# 6. Save Best Model Pipeline\n",
    "# ========================\n",
    "best_row = results_df.iloc[0]\n",
    "best_model_name = best_row[\"Model\"]\n",
    "final_pipeline = best_models[best_model_name]\n",
    "\n",
    "with open(\"final_pipeline.pkl\", \"wb\") as f:\n",
    "    pickle.dump(final_pipeline, f)\n",
    "\n",
    "print(f\"\\nFinal pipeline saved as final_pipeline.pkl ({best_model_name})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55cb8c9-6c7f-42b3-958f-40ea951f7ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
